{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9683275a-a215-4a8f-8266-4e186cefd687",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gladstone/engelhardt/home/lchumpitaz/gitclones/GPzoo/gpzoo/utilities.py:2: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import optim, distributions, nn\n",
    "import torch.nn.utils as nn_utils\n",
    "from tqdm import tqdm\n",
    "from gpzoo.gp import SVGP, VNNGP\n",
    "from gpzoo.kernels import NSF_RBF, RBF\n",
    "from gpzoo.likelihoods import NSF2\n",
    "from gpzoo.utilities import rescale_spatial_coords, dims_autocorr\n",
    "import squidpy as sq\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "from anndata import AnnData\n",
    "from squidpy.gr import spatial_neighbors,spatial_autocorr\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from matplotlib import animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b1a85ec-7e0b-4194-b5bc-4b164e03fdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "# use GPU if available\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "device\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "adata = sq.datasets.visium_hne_adata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f12a050f-97f4-4e2e-b84a-d34a1d0d8dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_benchmarking_experiments(X_train, Y_train, M, L, K, steps=1000, batch_size=64):\n",
    "    for k in tqdm(range(len(K))):\n",
    "        for m in range(len(M)):\n",
    "            for l in range(len(L)):\n",
    "                # make data dictionary\n",
    "                exp_data = {\n",
    "                    'model' :  [],\n",
    "                    'Z' : [],\n",
    "                    'L' : [],\n",
    "                    'K': [],\n",
    "                    'time' : []}\n",
    "                # run model\n",
    "                #idx = torch.multinomial(torch.ones(X_train.shape[0]), num_samples=M[m], replacement=False)\n",
    "                model = initialize_model(M[m], L[l], K[k], X_train, Y_train, 1.0, 1.0)\n",
    "                optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3)\n",
    "                model.to(device)\n",
    "                start_time = time.time()\n",
    "                X_train = torch.tensor(X_train, device='cuda', dtype=torch.float32, requires_grad=True)\n",
    "                losses, means, scales = train(model, optimizer, X_train, Y_train, device, steps=steps, E=10)\n",
    "                #losses, means, scales, idxs = train_batched(model, optimizer, X_train, Y_train, device, steps=steps, E=10, batch_size=batch_size)\n",
    "                end_time = time.time()\n",
    "                final_time = end_time - start_time\n",
    "\n",
    "                # update data dictionary\n",
    "                exp_data['L'].append(L)\n",
    "                exp_data['Z'].append(M)\n",
    "                exp_data['K'].append(K)\n",
    "                alg = 'NNNSF'\n",
    "                exp_data['model'].append(alg)\n",
    "                exp_data['time'].append(final_time)\n",
    "\n",
    "                # make + save loss plot\n",
    "                fig1, ax1 = plt.subplots()\n",
    "                plt.plot(losses)\n",
    "                plt.title(f\"Visium Losses\")\n",
    "                plt.close(fig1)\n",
    "\n",
    "                # make + save factors plot\n",
    "                size=5\n",
    "                #X_train = torch.tensor(X_train, device='cuda', dtype=torch.float32, requires_grad=True)\n",
    "                qF, qU, pU = model.prior(X_train)\n",
    "                loadings = torch.exp(qF.mean).detach().cpu().numpy()\n",
    "                del qF, qU, pU\n",
    "                with torch.no_grad():\n",
    "                    if device.type=='cuda':\n",
    "                        torch.cuda.empty_cache()\n",
    "                X_train = X_train.detach().cpu().numpy()\n",
    "                moran_idx, moranI = dims_autocorr(np.log(loadings).T, X_train)\n",
    "\n",
    "                fig2, ax2 = plt.subplots(2, 5, figsize=(size*5, size*2), tight_layout=True)\n",
    "                fig2.suptitle(\"NNNSF Factors\", size=20)\n",
    "                plot(X_train, loadings, moran_idx, L[l], ax=ax2, size=5, alpha=0.8)\n",
    "                plt.close(fig2)\n",
    "\n",
    "                # make + save animation\n",
    "                fig3, ax = plt.subplots(2, 5, figsize=(size*5, size*2), tight_layout=True)\n",
    "                fig3.suptitle(\"NNNSF Factors\", size=20)\n",
    "\n",
    "                def update(iteration):\n",
    "                    for ax_row in ax:\n",
    "                        for element in ax_row:\n",
    "                            element.cla()\n",
    "                    curr_mean = means[iteration]\n",
    "                    #curr_idx = idxs[iteration]\n",
    "                    plot(X_train, curr_mean, moran_idx, L=10, ax=ax, size=size, alpha=0.9)\n",
    "\n",
    "                anim = FuncAnimation(fig3, update, frames=np.arange(0, len(means), 1), interval=100)\n",
    "                plt.show()\n",
    "                plt.close()\n",
    "                anim.save(f'.visium_K={K[k]}_Z={M[m]}_factors_anim.gif', writer=\"pillow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffcba89e-21ab-4056-8c90-04c845a3f65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, X, y, device, steps=200, E=10, batch_size=64, **kwargs):\n",
    "    losses = []\n",
    "    means = []\n",
    "    scales = []\n",
    "    #idxs = []\n",
    "    \n",
    "    for it in tqdm(range(steps)):   \n",
    "        idx = torch.multinomial(torch.ones(X.shape[0]), num_samples=batch_size, replacement=False)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pY, qF, qU, pU = model.forward(X=X, E=E, **kwargs)\n",
    "\n",
    "        logpY = pY.log_prob(y)\n",
    "\n",
    "        ELBO = (logpY).mean(axis=0).sum()\n",
    "        ELBO -= torch.sum(distributions.kl_divergence(qU, pU))\n",
    "\n",
    "        loss = -ELBO\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        if (it%10)==0:\n",
    "            #idxs.append(idx.detach().cpu().numpy())\n",
    "            means.append(torch.exp(qF.mean.detach().cpu()).numpy())\n",
    "            scales.append(qF.scale.detach().cpu().numpy())\n",
    "\n",
    "    with torch.no_grad():\n",
    "        if device.type=='cuda':\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    return losses, means, scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b0342d6-a32c-48a3-89e5-a3316680697d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(M, L, K, X, Y, sigma=1.0, lengthscale=1.0):\n",
    "    idx = torch.multinomial(torch.ones(X.shape[0]), num_samples=M, replacement=False)\n",
    "    kernel = NSF_RBF(L=L, sigma=1.0, lengthscale=1.0)\n",
    "    gp = VNNGP(kernel, M=M, jitter=1e-2, K=K)\n",
    "    gp.Lu = nn.Parameter(torch.eye(M).expand(L, M, M).clone())\n",
    "    gp.mu = nn.Parameter(torch.randn((L, M)))\n",
    "    gp.Z = nn.Parameter(torch.tensor(X[idx]))\n",
    "\n",
    "    model = NSF2(gp=gp, y=Y, L=L)\n",
    "    model.prior.kernel.lengthscale.requires_grad = True\n",
    "    model.prior.kernel.sigma.requires_grad = False\n",
    "    model.prior.Z.requires_grad = False\n",
    "    model.prior.mu.requires_grad = True\n",
    "    model.prior.Lu.requires_grad = True\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d5f1c97-909d-4b47-bb8d-5af01348311d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dims_autocorr(factors,coords,sort=True):\n",
    "    \"\"\"\n",
    "    factors: (num observations) x (num latent dimensions) array\n",
    "    coords: (num observations) x (num spatial dimensions) array\n",
    "    sort: if True (default), returns the index and I statistics in decreasing\n",
    "    order of autocorrelation. If False, returns the index and I statistics\n",
    "    according to the ordering of factors.\n",
    "\n",
    "    returns: an integer array of length (num latent dims), \"idx\"\n",
    "    and a numpy array containing the Moran's I values for each dimension\n",
    "\n",
    "    indexing factors[:,idx] will sort the factors in decreasing order of spatial\n",
    "    autocorrelation.\n",
    "    \"\"\"\n",
    "    #from anndata import AnnData\n",
    "    #from squidpy.gr import spatial_neighbors,spatial_autocorr\n",
    "\n",
    "    ad = AnnData(X=factors,obsm={\"spatial\":coords})\n",
    "    spatial_neighbors(ad)\n",
    "    df = spatial_autocorr(ad,mode=\"moran\",copy=True)\n",
    "    if not sort: #revert to original sort order\n",
    "        df.sort_index(inplace=True)\n",
    "    \n",
    "    idx = np.array([int(i) for i in df.index])\n",
    "    return idx,df[\"I\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "186c1b8b-356d-4aaf-a308-e34ca94067dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(X_train, factors, moran_idx, L, ax=None, size=7, alpha=0.9):\n",
    "    L=10\n",
    "    max_val = np.percentile(factors, 99)\n",
    "    min_val = np.percentile(factors, 1)\n",
    "    #size = 5\n",
    "    #fig, ax = plt.subplots(L//5, 5, figsize=(size*5, size*2), tight_layout=True)\n",
    "    #fig.suptitle(\"NNNSF Factors\", size=25)\n",
    "    for i in range(L):\n",
    "        plt.subplot(L//5, 5, i+1)\n",
    "        \n",
    "        curr_ax = ax[i//5, i%5]\n",
    "        curr_ax.scatter(X_train[:, 0], X_train[:,1], c=factors[moran_idx][i], vmin=min_val, vmax=max_val, alpha=alpha, cmap='turbo')#, s=0.1)\n",
    "        curr_ax.set_xlim([X_train[:,0].min()*1.1, X_train[:,0].max()*1.1])\n",
    "        curr_ax.set_ylim([X_train[:,1].min()*1.1, X_train[:,1].max()*1.1])\n",
    "        curr_ax.invert_yaxis()\n",
    "        curr_ax.set_xticks([])\n",
    "        curr_ax.set_yticks([])\n",
    "        curr_ax.set_facecolor('xkcd:gray')\n",
    "\n",
    "\n",
    "def plot_anim(factors, moran_idx, curr_idx, L, ax=None, size=7, alpha=0.9):\n",
    "    max_val = np.percentile(factors, 99)\n",
    "    min_val = np.percentile(factors, 1)\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(4, 5, figsize=(size*5, size*4), tight_layout=True)\n",
    "    for i in range(L):\n",
    "        plt.subplot(L//5, 5, i+1)\n",
    "        curr_ax = ax[i//5, i%5]\n",
    "        curr_ax.scatter(X[curr_idx, 0], X[curr_idx,1], c=factors[moran_idx][i], vmin=min_val, vmax=max_val, alpha=alpha, cmap='turbo')#, s=0.1)\n",
    "        curr_ax.invert_yaxis()\n",
    "        curr_ax.set_xticks([])\n",
    "        curr_ax.set_yticks([])\n",
    "        curr_ax.set_facecolor('xkcd:gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "122a779e-c347-48f4-94bd-1ca8468dc6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\t# load data\n",
    "\tY_sums = np.array(np.sum(adata.raw.X > 0, axis=0))[0]\n",
    "\tY = np.array(adata.raw.X[:, Y_sums>200].todense(), dtype=int).T\n",
    "\tX = adata.obsm['spatial']\n",
    "\tX = X.astype('float64')\n",
    "\tX = rescale_spatial_coords(X)\n",
    "\t\n",
    "\tX = torch.tensor(X, dtype=torch.float)\n",
    "\tY = torch.tensor(Y, dtype=torch.float)\t\n",
    "\n",
    "\tX_train = X.to(device)\n",
    "\tY_train = Y.to(device)\n",
    "\tneighbors = [8]#,2,3,4,5,6,7,8,9,10]\n",
    "\tinducing_pts = [1000] #[100, 500, 1000, 1500, 2000, 2500, 3000]\n",
    "\tgps = [10]\n",
    "\trun_benchmarking_experiments(X_train, Y_train, inducing_pts, gps, neighbors, steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a0dc07e-9217-407e-956f-c9c208e8719b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                         | 0/1 [00:00<?, ?it/s]/tmp/ipykernel_3649068/1509992282.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp.Z = nn.Parameter(torch.tensor(X[idx]))\n",
      "/tmp/ipykernel_3649068/2662142739.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train = torch.tensor(X_train, device='cuda', dtype=torch.float32, requires_grad=True)\n",
      "\n",
      "  0%|                                                                                                      | 0/1000 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|                                                                                                         | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "forward() got an unexpected keyword argument 'return_distance'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 17\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m inducing_pts \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1000\u001b[39m] \u001b[38;5;66;03m#[100, 500, 1000, 1500, 2000, 2500, 3000]\u001b[39;00m\n\u001b[1;32m     16\u001b[0m gps \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m10\u001b[39m]\n\u001b[0;32m---> 17\u001b[0m \u001b[43mrun_benchmarking_experiments\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minducing_pts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneighbors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 19\u001b[0m, in \u001b[0;36mrun_benchmarking_experiments\u001b[0;34m(X_train, Y_train, M, L, K, steps, batch_size)\u001b[0m\n\u001b[1;32m     17\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     18\u001b[0m X_train \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(X_train, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32, requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 19\u001b[0m losses, means, scales \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mE\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m#losses, means, scales, idxs = train_batched(model, optimizer, X_train, Y_train, device, steps=steps, E=10, batch_size=batch_size)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "Cell \u001b[0;32mIn[4], line 11\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, X, y, device, steps, E, batch_size, **kwargs)\u001b[0m\n\u001b[1;32m      8\u001b[0m idx \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmultinomial(torch\u001b[38;5;241m.\u001b[39mones(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]), num_samples\u001b[38;5;241m=\u001b[39mbatch_size, replacement\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     10\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 11\u001b[0m pY, qF, qU, pU \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mE\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m logpY \u001b[38;5;241m=\u001b[39m pY\u001b[38;5;241m.\u001b[39mlog_prob(y)\n\u001b[1;32m     15\u001b[0m ELBO \u001b[38;5;241m=\u001b[39m (logpY)\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39msum()\n",
      "File \u001b[0;32m~/gitclones/GPzoo/gpzoo/likelihoods.py:65\u001b[0m, in \u001b[0;36mNSF2.forward\u001b[0;34m(self, X, E, verbose, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, E\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 65\u001b[0m   qF, qU, pU \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprior\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m   F \u001b[38;5;241m=\u001b[39m qF\u001b[38;5;241m.\u001b[39mrsample((E,))\n\u001b[1;32m     67\u001b[0m   Z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_rate(F)\n",
      "File \u001b[0;32m~/miniconda3/envs/gpzoo/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/gpzoo/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/gitclones/GPzoo/gpzoo/gp.py:31\u001b[0m, in \u001b[0;36mVNNGP.forward\u001b[0;34m(self, X, verbose)\u001b[0m\n\u001b[1;32m     27\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcalculating Kxx\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     28\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKxx.shape\u001b[39m\u001b[38;5;124m'\u001b[39m, Kxx\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 31\u001b[0m Kxz, distances \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mZ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m Kxz_shape \u001b[38;5;241m=\u001b[39m Kxz\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m     34\u001b[0m Kxz \u001b[38;5;241m=\u001b[39m Kxz\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, Kxz_shape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;66;03m# (... x N) x M\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/gpzoo/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/gpzoo/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() got an unexpected keyword argument 'return_distance'"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee5ae32-fbc5-48f3-bb4f-c460f349c77f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
